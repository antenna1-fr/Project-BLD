{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1178e762b678273",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:51:08.862916Z",
     "start_time": "2025-11-19T05:51:06.656496Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\venv311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# XGB_Prototype_Modular.ipynb (Cell 1)\n",
    "# Modularized version using refactored components\n",
    "# =========================\n",
    "from __future__ import annotations\n",
    "\n",
    "import gc, os, sys, math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost.callback import EarlyStopping, EvaluationMonitor\n",
    "\n",
    "import shap\n",
    "import optuna\n",
    "from packaging import version\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# ---- project config ----\n",
    "config_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(config_path)\n",
    "import config as config\n",
    "\n",
    "# ---- Import modularized components ----\n",
    "from src.data.tabular_dataset import build_leak_proof_dataset\n",
    "from src.data.storage import DataStorage\n",
    "from src.backtest.splits import purged_time_splits, get_last_split\n",
    "from src.backtest.engine import run_backtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4296b65f420218cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:51:17.297550Z",
     "start_time": "2025-11-19T05:51:17.294294Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- paths ----\n",
    "DATASET_PATH = str(config.PROCESSED_DATA_PATH)\n",
    "OUTPUT_PLOT = str(config.XGB_CONFUSION_MATRIX_PLOT)\n",
    "OUTPUT_PREDICTIONS = str(config.PREDICTIONS_CSV)\n",
    "OUTPUT_SHAP = str(config.OUTPUTS_DIR / \"shap_feature_importance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3a67cf2440956e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:52:08.500677Z",
     "start_time": "2025-11-19T05:51:19.196317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Loading data from C:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\data\\processed\\improved_normalized_labeled.parquet\n",
      "[dataset] Rows: 27,405,019 | Class counts (−1,0,1): {-1:3412420, 0:19793980, 1:4198619}\n",
      "[dataset] Features: 99 | Excluded 12 passthrough/leak columns\n",
      "[dataset] Post-filter class counts: {-1:3179040, 0:18494207, 1:3887941}\n",
      "[modular] Dataset ready: 25,561,188 rows, 99 features\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# MODULAR DATA LOADING (Cell 3)\n",
    "# Uses DataStorage + build_leak_proof_dataset for consistent loading\n",
    "# This limits to first 1 million rows as requested\n",
    "# =========================\n",
    "\n",
    "print(f\"[modular] Loading data from {DATASET_PATH}\")\n",
    "\n",
    "# Use DataStorage (DuckDB) to read Parquet/CSV efficiently\n",
    "storage = DataStorage(processed_path=DATASET_PATH)\n",
    "df_raw = storage.load_full_table()\n",
    "\n",
    "# Use the modularized build_leak_proof_dataset function\n",
    "df, y_dir, y_enc, feature_cols = build_leak_proof_dataset(\n",
    "    df_raw,\n",
    "    label_params={\n",
    "        'up_tau': 0.25,\n",
    "        'dn_tau_base': 0.08,\n",
    "        'use_vol_scaled_dn': False,\n",
    "    },\n",
    "    downcast_float64=True,\n",
    "    require_tradable=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Store labels in df for compatibility\n",
    "y = y_enc\n",
    "print(f\"[modular] Dataset ready: {len(df):,} rows, {len(feature_cols)} features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6019a6625ce917e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:52:14.280922Z",
     "start_time": "2025-11-19T05:52:12.724124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Creating train/val split using purged_time_splits...\n",
      "[modular] Train: 21,300,990 | Val: 4,260,198\n",
      "[modular] Class weights: {-1:2.6213, 0:0.4699, 1:2.0383}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Split using modularized splits module (Cell 4)\n",
    "# =========================\n",
    "print(\"[modular] Creating train/val split using purged_time_splits...\")\n",
    "\n",
    "# Use the modularized splitting function\n",
    "train_idx, val_idx = get_last_split(df, n_splits=5, embargo=0)\n",
    "\n",
    "# Extract features for training\n",
    "X = df[feature_cols].copy()\n",
    "X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "# Compute class weights\n",
    "tr_counts = np.bincount(y_tr, minlength=3)\n",
    "tr_counts = np.maximum(tr_counts, 1)\n",
    "w_per_class = tr_counts.sum() / (3.0 * tr_counts)\n",
    "w_tr = w_per_class[y_tr].astype(\"float32\")\n",
    "\n",
    "print(f\"[modular] Train: {len(X_tr):,} | Val: {len(X_val):,}\")\n",
    "print(f\"[modular] Class weights: {{-1:{float(w_per_class[0]):.4f}, \"\n",
    "      f\"0:{float(w_per_class[1]):.4f}, 1:{float(w_per_class[2]):.4f}}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60e425d7803179a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:52:20.713044Z",
     "start_time": "2025-11-19T05:52:20.709465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Running leak check...\n",
      "[sanity] target-like columns present: ['target_min_abs', 'target_max_abs', 'target_min_rel', 'target_max_rel', 'target_q_up_abs', 'target_q_dn_abs', 'target_q_up_rel', 'target_q_dn_rel']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Leak check (Cell 5)\n",
    "# =========================\n",
    "print(\"[modular] Running leak check...\")\n",
    "sus = [c for c in df.columns if c.startswith(\"target_\")]\n",
    "print(f\"[sanity] target-like columns present: {sus[:8]}{'...' if len(sus)>8 else ''}\")\n",
    "\n",
    "# Inverse mapping for directional labels\n",
    "_inv = np.array([-1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "977234e5b36c8bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:52:26.471928Z",
     "start_time": "2025-11-19T05:52:26.467428Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Training utilities (Cell 6)\n",
    "# =========================\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "USE_GPU = True\n",
    "USE_OPTUNA = False\n",
    "N_TRIALS = 10\n",
    "LOAD_EXISTING_MODEL = False\n",
    "SAVE_MODEL_AFTER_TRAIN = True\n",
    "OVERWRITE_SAVED_PARAMS = True\n",
    "\n",
    "MODEL_DIR = Path(str(config.OUTPUTS_DIR)) / \"xgb\"\n",
    "PARAMS_PATH = MODEL_DIR / \"xgb_best_params.json\"\n",
    "MODEL_PATH = MODEL_DIR / \"xgb_model.ubj\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import json\n",
    "\n",
    "def _save_json(obj, p: Path):\n",
    "    with open(p, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2)\n",
    "\n",
    "def _load_json(p: Path):\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def _np_view(df):\n",
    "    return df.to_numpy(dtype=np.float32, copy=False)\n",
    "\n",
    "def _merge_common(best: dict, use_gpu: bool) -> dict:\n",
    "    common = {\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"num_class\": 3,\n",
    "        \"eval_metric\": \"mlogloss\",\n",
    "        \"random_state\": RANDOM_SEED,\n",
    "        \"n_jobs\": max(1, os.cpu_count()-1),\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"device\": (\"cuda\" if use_gpu else \"cpu\"),\n",
    "    }\n",
    "    merged = {**common, **best}\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf388d9c7dc34c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:52:30.788817Z",
     "start_time": "2025-11-19T05:52:30.783993Z"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Opportunity coverage helper (Cell 7)\n",
    "# =========================\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "def _forward_extrema(df_item, horizon):\n",
    "    \"\"\"Compute forward max/min returns for a single item's time series.\"\"\"\n",
    "    x = df_item['mid_price'].to_numpy()\n",
    "    if len(x) < horizon:\n",
    "        out = df_item[['timestamp','item','mid_price']].copy()\n",
    "        out['fwd_up_ret'] = np.nan\n",
    "        out['fwd_dn_ret'] = np.nan\n",
    "        return out\n",
    "    win = sliding_window_view(x, horizon)\n",
    "    fwd_max = np.concatenate([win.max(1), np.full(horizon-1, np.nan)])\n",
    "    fwd_min = np.concatenate([win.min(1), np.full(horizon-1, np.nan)])\n",
    "    out = df_item[['timestamp','item','mid_price']].copy()\n",
    "    out['fwd_up_ret'] = (fwd_max - x) / x\n",
    "    out['fwd_dn_ret'] = (x - fwd_min) / x\n",
    "    return out\n",
    "\n",
    "def opportunity_coverage(prices, preds, horizon=60, up_tau=0.03, dn_tau=0.03, score_col='score'):\n",
    "    \"\"\"\n",
    "    Compute opportunity coverage metrics.\n",
    "\n",
    "    Measures how well the model captures good trading opportunities\n",
    "    within the specified horizon.\n",
    "    \"\"\"\n",
    "    preds = preds.copy()\n",
    "    if score_col not in preds:\n",
    "        preds['score'] = preds['Pp1'] - preds['Pm1']\n",
    "    prices = prices.sort_values(['item','timestamp']).copy()\n",
    "    opp = (prices.groupby('item', group_keys=False)\n",
    "                 .apply(lambda g: _forward_extrema(g, horizon)))\n",
    "\n",
    "    joined = preds.merge(opp, on=['item','timestamp'], how='inner')\n",
    "    joined['good_up']  = joined['fwd_up_ret'] >= up_tau\n",
    "    joined['good_dn']  = joined['fwd_dn_ret'] >= dn_tau\n",
    "    joined['flag_buy'] = joined['score'] > 0\n",
    "    joined['flag_sell']= joined['score'] < 0\n",
    "\n",
    "    metrics = {\n",
    "        'recall@good_up': (joined['flag_buy'] & joined['good_up']).sum() / max(1, joined['good_up'].sum()),\n",
    "        'precision@buy':  (joined['flag_buy'] & (joined['fwd_up_ret']>0)).sum() / max(1, joined['flag_buy'].sum()),\n",
    "        'recall@good_dn': (joined['flag_sell'] & joined['good_dn']).sum() / max(1, joined['good_dn'].sum()),\n",
    "        'precision@sell': (joined['flag_sell'] & (joined['fwd_dn_ret']>0)).sum() / max(1, joined['flag_sell'].sum()),\n",
    "        'coverage%':      100 * joined.groupby('timestamp')['flag_buy'].max().mean()\n",
    "    }\n",
    "    return pd.Series(metrics), joined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d40bddb27ccef3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:55:16.219342Z",
     "start_time": "2025-11-19T05:52:34.217657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Training classifier...\n",
      "[train] Optuna disabled — loaded saved params from C:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\outputs\\xgb\\xgb_best_params.json\n",
      "[train] Saved model → C:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\outputs\\xgb\\xgb_model.ubj\n",
      "[modular] Classifier params: {'framework': 'xgb', 'tree_method': 'hist', 'objective': 'multi:softprob', 'num_class': 3, 'eval_metric': 'mlogloss', 'random_state': 42, 'n_jobs': 31, 'early_stopping_rounds': 100, 'device': 'cuda', 'n_estimators': 1056, 'max_depth': 17, 'learning_rate': 0.07630560271534147, 'subsample': 0.8542703315240835, 'colsample_bytree': 0.8777243706586128, 'min_child_weight': 1.5109545399199749, 'reg_lambda': 0.4102689328356389, 'reg_alpha': 0.00541289211202473, 'gamma': 0.3252579649263976, 'max_bin': 493, 'grow_policy': 'depthwise'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2837"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# Training function (Cell 8)\n",
    "# =========================\n",
    "def train_classifier(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    w_tr=None,\n",
    "    n_trials=10,\n",
    "    use_gpu=USE_GPU,\n",
    "    use_optuna=USE_OPTUNA,\n",
    "    params_path=PARAMS_PATH,\n",
    "    model_path=MODEL_PATH,\n",
    "    load_existing_model=LOAD_EXISTING_MODEL,\n",
    "    save_model_after_train=SAVE_MODEL_AFTER_TRAIN,\n",
    "    overwrite_saved_params=OVERWRITE_SAVED_PARAMS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train XGBoost classifier with optional HPO.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fast path: load existing model\n",
    "    if load_existing_model and Path(model_path).exists():\n",
    "        print(f\"[train] Loading existing model → {model_path}\")\n",
    "        clf = xgb.XGBClassifier()\n",
    "        clf.load_model(str(model_path))\n",
    "        if not hasattr(clf, \"classes_\") or getattr(clf, \"classes_\", None) is None:\n",
    "            clf.classes_ = np.array([0,1,2], dtype=np.int64)\n",
    "            clf.n_classes_ = 3\n",
    "        if Path(params_path).exists():\n",
    "            params = _load_json(params_path)\n",
    "        else:\n",
    "            params = {\"framework\": \"xgb\", \"loaded_from_model\": True}\n",
    "        return clf, params\n",
    "\n",
    "    # Load saved params if not using Optuna\n",
    "    loaded_params = None\n",
    "    if not use_optuna and Path(params_path).exists():\n",
    "        loaded_params = _load_json(params_path)\n",
    "        print(f\"[train] Optuna disabled — loaded saved params from {params_path}\")\n",
    "\n",
    "    # Prepare NumPy views once\n",
    "    X_tr_np  = _np_view(X_tr)\n",
    "    X_val_np = _np_view(X_val)\n",
    "\n",
    "    # Precompute validation metadata once (used by opportunity_coverage)\n",
    "    # NOTE: df and val_idx are taken from outer scope (your notebook)\n",
    "    val_meta = df.loc[val_idx, ['timestamp','item','mid_price']].reset_index(drop=True)\n",
    "    prices_val = df.loc[val_idx, ['timestamp','item','mid_price']]\n",
    "\n",
    "    # ===== HPO path =====\n",
    "    if use_optuna and loaded_params is None:\n",
    "        print(f\"[train] Running Optuna for {n_trials} trials...\")\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED),\n",
    "            pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=50),\n",
    "        )\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                \"n_estimators\":       trial.suggest_int(\"n_estimators\", 600, 1600),\n",
    "                \"max_depth\":          trial.suggest_int(\"max_depth\", 10, 18),\n",
    "                \"learning_rate\":      trial.suggest_float(\"learning_rate\", 0.06, 0.20, log=True),\n",
    "                \"subsample\":          trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "                \"colsample_bytree\":   trial.suggest_float(\"colsample_bytree\", 0.7, 1.0),\n",
    "                \"min_child_weight\":   trial.suggest_float(\"min_child_weight\", 1.0, 12.0),\n",
    "                \"reg_lambda\":         trial.suggest_float(\"reg_lambda\", 1e-3, 20.0, log=True),\n",
    "                \"reg_alpha\":          trial.suggest_float(\"reg_alpha\", 1e-3, 20.0, log=True),\n",
    "                \"gamma\":              trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "                \"max_bin\":            trial.suggest_int(\"max_bin\", 128, 512),\n",
    "                \"grow_policy\":        trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"]),\n",
    "            }\n",
    "            params = _merge_common(params, use_gpu)\n",
    "\n",
    "            clf = xgb.XGBClassifier(**params)\n",
    "            clf.fit(\n",
    "                X_tr_np,\n",
    "                y_tr,\n",
    "                sample_weight=w_tr,\n",
    "                eval_set=[(X_val_np, y_val)],\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            # ---- Validation predictions (GPU) ----\n",
    "            # Using sklearn API here avoids extra DMatrix allocation every trial.\n",
    "            best_it = getattr(clf, \"best_iteration_\", None)\n",
    "            if best_it is not None:\n",
    "                y_proba = clf.predict_proba(X_val_np, iteration_range=(0, int(best_it) + 1))\n",
    "            else:\n",
    "                y_proba = clf.predict_proba(X_val_np)\n",
    "            y_proba = np.asarray(y_proba)\n",
    "            yhat = y_proba.argmax(axis=1)\n",
    "\n",
    "            # F1 metric\n",
    "            f1 = f1_score(y_val, yhat, average=\"macro\")\n",
    "\n",
    "            # Profit-aware proxy (CPU-heavy part)\n",
    "            try:\n",
    "                classes_enc = np.asarray(getattr(clf, \"classes_\", np.array([0,1,2])))\n",
    "                classes_dec = _inv[classes_enc]\n",
    "                buy_idx  = int(np.where(classes_dec == 1)[0][0]) if (classes_dec == 1).any() else (y_proba.shape[1]-1)\n",
    "                sell_idx = int(np.where(classes_dec == -1)[0][0]) if (classes_dec == -1).any() else 0\n",
    "                score = y_proba[:, buy_idx] - y_proba[:, sell_idx]\n",
    "\n",
    "                preds = pd.DataFrame({\n",
    "                    'timestamp': val_meta['timestamp'].values,\n",
    "                    'item':      val_meta['item'].values,\n",
    "                    'mid_price': val_meta['mid_price'].values,\n",
    "                    'score':     score.astype('float32'),\n",
    "                })\n",
    "\n",
    "                metr, _ = opportunity_coverage(\n",
    "                    prices=prices_val,  # already a slice, no extra copy\n",
    "                    preds=preds[['timestamp','item','mid_price','score']],\n",
    "                    horizon=60,\n",
    "                    up_tau=0.03,\n",
    "                    dn_tau=0.03,\n",
    "                    score_col='score',\n",
    "                )\n",
    "                profit_proxy = float(\n",
    "                    metr.get('precision@buy', 0.0) * metr.get('recall@good_up', 0.0)\n",
    "                )\n",
    "            except Exception:\n",
    "                profit_proxy = 0.0\n",
    "\n",
    "            combo = 0.6 * profit_proxy + 0.4 * f1\n",
    "\n",
    "            trial.report(combo, step=int(best_it) if best_it is not None else 0)\n",
    "            if trial.should_prune():\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            return combo\n",
    "\n",
    "        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "        best = study.best_params\n",
    "        best = _merge_common(best, use_gpu)\n",
    "        if overwrite_saved_params:\n",
    "            _save_json(best, params_path)\n",
    "            print(f\"[train] Saved best params → {params_path}\")\n",
    "\n",
    "    # ===== Saved/baseline params path =====\n",
    "    else:\n",
    "        if loaded_params is not None:\n",
    "            best = loaded_params\n",
    "        else:\n",
    "            print(\"[train] Optuna disabled and no params file found — using baseline params.\")\n",
    "            best = {\n",
    "                \"n_estimators\": 1050,\n",
    "                \"max_depth\": 17,\n",
    "                \"learning_rate\": 0.076,\n",
    "                \"subsample\": 0.854,\n",
    "                \"colsample_bytree\": 0.877,\n",
    "                \"min_child_weight\": 1.51,\n",
    "                \"reg_lambda\": .41,\n",
    "                \"reg_alpha\": 0.0054,\n",
    "                \"gamma\": 0.325,\n",
    "                \"max_bin\": 493,\n",
    "                \"grow_policy\": \"depthwise\",\n",
    "            }\n",
    "        best = _merge_common(best, use_gpu)\n",
    "\n",
    "    # ===== Final train with chosen params =====\n",
    "    clf = xgb.XGBClassifier(**best)\n",
    "    clf.fit(\n",
    "        X_tr_np,\n",
    "        y_tr,\n",
    "        sample_weight=w_tr,\n",
    "        eval_set=[(X_val_np, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    if save_model_after_train:\n",
    "        try:\n",
    "            clf.save_model(str(model_path))\n",
    "            print(f\"[train] Saved model → {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[train][warn] Could not save model: {e}\")\n",
    "    try:\n",
    "        _save_json(best, params_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[train][warn] Could not save params: {e}\")\n",
    "\n",
    "    return clf, {\"framework\": \"xgb\", **best}\n",
    "\n",
    "\n",
    "# ---- Run training ----\n",
    "print(\"[modular] Training classifier...\")\n",
    "clf, params = train_classifier(\n",
    "    X_tr, y_tr, X_val, y_val,\n",
    "    w_tr=w_tr,\n",
    "    n_trials=N_TRIALS,\n",
    "    use_gpu=USE_GPU,\n",
    "    use_optuna=USE_OPTUNA,\n",
    ")\n",
    "print(\"[modular] Classifier params:\", params)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782ba6bc29968ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\venv311\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [15:23:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cal] Base macro-F1 (no calibration): 0.5480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\venv311\\Lib\\site-packages\\sklearn\\calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cal] Calibrated macro-F1: 0.4980\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Calibration (Cell 9)\n",
    "# =========================\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "xgb_params = {k: v for k, v in params.items() if k != \"framework\"}\n",
    "\n",
    "base = XGBClassifier(**xgb_params)\n",
    "base.fit(X_tr, y_tr, sample_weight=w_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "pred_base = base.predict(X_val)\n",
    "f1_base = f1_score(y_val, pred_base, average=\"macro\")\n",
    "print(f\"[cal] Base macro-F1 (no calibration): {f1_base:.4f}\")\n",
    "\n",
    "DO_CALIBRATE = True\n",
    "if DO_CALIBRATE:\n",
    "    clf = CalibratedClassifierCV(base, method=\"sigmoid\", cv=\"prefit\")\n",
    "    clf.fit(X_val, y_val)\n",
    "    pred_cal = clf.predict(X_val)\n",
    "    f1_cal = f1_score(y_val, pred_cal, average=\"macro\")\n",
    "    print(f\"[cal] Calibrated macro-F1: {f1_cal:.4f}\")\n",
    "else:\n",
    "    clf = base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e244ebca6900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Build predictions DataFrame (Cell 10)\n",
    "# =========================\n",
    "DATA_DF = df\n",
    "META_COLS = ['timestamp','item','mid_price']\n",
    "\n",
    "IDX = df.index[val_idx]\n",
    "test_meta = df.loc[IDX, META_COLS].reset_index(drop=True).copy()\n",
    "test_meta['vol_est'] = (df.loc[IDX, 'vol_est'].values\n",
    "                        if 'vol_est' in df.columns else 1.0)\n",
    "\n",
    "proba_val = getattr(clf, \"predict_proba\", lambda X: None)(X_val)\n",
    "\n",
    "classes_enc = np.asarray(getattr(clf, \"classes_\", np.array([0,1,2])))\n",
    "classes_dec = _inv[classes_enc]\n",
    "\n",
    "proba_df = pd.DataFrame(proba_val, columns=[f'P{c}' for c in classes_dec])\n",
    "\n",
    "rename = {}\n",
    "for c in classes_dec:\n",
    "    if c == -1: rename[f'P{c}'] = 'Pm1'\n",
    "    elif c == 0: rename[f'P{c}'] = 'P0'\n",
    "    elif c == 1: rename[f'P{c}'] = 'Pp1'\n",
    "proba_df = proba_df.rename(columns=rename)\n",
    "for col in ['Pm1','P0','Pp1']:\n",
    "    if col not in proba_df.columns:\n",
    "        proba_df[col] = 0.0\n",
    "\n",
    "preds_test = pd.concat([test_meta, proba_df], axis=1).reset_index(drop=True)\n",
    "\n",
    "assert isinstance(preds_test, pd.DataFrame)\n",
    "assert {'timestamp','item','mid_price','Pm1','P0','Pp1'}.issubset(preds_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49da013ef443cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added score columns: ['score_buy', 'score_sell', 'score']\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Synthesize scores (Cell 11)\n",
    "# =========================\n",
    "def _get_first(df, names, default=np.nan):\n",
    "    for n in names:\n",
    "        if n in df.columns:\n",
    "            return df[n].astype(float)\n",
    "    return np.full(len(df), default, dtype=float)\n",
    "\n",
    "p_pos = _get_first(preds_test, ['Pp1','P1','P(1)','prob_1','proba_1'], default=np.nan)\n",
    "p_neg = _get_first(preds_test, ['Pm1','P-1','P(-1)','prob_-1','proba_-1'], default=np.nan)\n",
    "p_neu = _get_first(preds_test, ['P0','P(0)','prob_0','proba_0'], default=np.nan)\n",
    "\n",
    "has_real_sell = np.isfinite(p_neg).any() and (np.nanmax(p_neg) > 0)\n",
    "\n",
    "if has_real_sell:\n",
    "    preds_test['score_buy']  = p_pos - p_neg\n",
    "    preds_test['score_sell'] = p_neg - p_pos\n",
    "else:\n",
    "    preds_test['score_buy']  = p_pos - (p_neu if np.isfinite(p_neu).any() else 0.0)\n",
    "    preds_test['score_sell'] = np.nan\n",
    "\n",
    "if 'score' not in preds_test.columns:\n",
    "    preds_test['score'] = preds_test['score_buy']\n",
    "\n",
    "print(\"Added score columns:\", [c for c in ['score_buy','score_sell','score'] if c in preds_test.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba8dac0dd39ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reyno\\AppData\\Local\\Temp\\ipykernel_30172\\3340249347.py:34: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: _forward_extrema(g, horizon)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Opportunity coverage metrics:\n",
      "recall@good_up     0.649955\n",
      "precision@buy      0.686705\n",
      "recall@good_dn     0.577205\n",
      "precision@sell     0.754159\n",
      "coverage%         99.717354\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Opportunity coverage metrics (Cell 12)\n",
    "# =========================\n",
    "HORIZON = 60\n",
    "UP_TAU  = 0.03\n",
    "DN_TAU  = 0.03\n",
    "\n",
    "prices_test = df.loc[val_idx, ['timestamp','item','mid_price']].copy()\n",
    "opp_metrics, opp_joined = opportunity_coverage(prices_test, preds_test,\n",
    "                                               horizon=HORIZON, up_tau=UP_TAU, dn_tau=DN_TAU)\n",
    "print(\"[modular] Opportunity coverage metrics:\")\n",
    "print(opp_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5458a3b0efa2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] F1 (macro): 0.5480\n",
      "[modular] F1 (weighted): 0.7619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.4449    0.3734    0.4061    470315\n",
      "           0     0.8820    0.8332    0.8569   3385403\n",
      "           1     0.3059    0.5045    0.3809    404480\n",
      "\n",
      "    accuracy                         0.7513   4260198\n",
      "   macro avg     0.5443    0.5704    0.5480   4260198\n",
      "weighted avg     0.7790    0.7513    0.7619   4260198\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# Validation metrics & confusion matrix (Cell 13)\n",
    "# =========================\n",
    "y_val_hat = clf.predict(X_val)\n",
    "proba_val = getattr(clf, \"predict_proba\", lambda X: None)(X_val)\n",
    "\n",
    "macro_f1 = f1_score(y_val, y_val_hat, average=\"macro\")\n",
    "weighted_f1 = f1_score(y_val, y_val_hat, average=\"weighted\")\n",
    "print(f\"[modular] F1 (macro): {macro_f1:.4f}\")\n",
    "print(f\"[modular] F1 (weighted): {weighted_f1:.4f}\")\n",
    "print(classification_report(y_val, y_val_hat, target_names=[\"-1\",\"0\",\"1\"], digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_val_hat, labels=[0,1,2])\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "ax = plt.gca()\n",
    "im = ax.imshow(cm, interpolation=\"nearest\")\n",
    "ax.set_title(\"3-class Direction (val) â€” Confusion Matrix\")\n",
    "ax.set_xticks([0,1,2]); ax.set_xticklabels([\"-1\",\"0\",\"1\"])\n",
    "ax.set_yticks([0,1,2]); ax.set_yticklabels([\"-1\",\"0\",\"1\"])\n",
    "for (i, j), v in np.ndenumerate(cm):\n",
    "    ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(OUTPUT_PLOT, dpi=160)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8a47e708a1d302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Saved predictions â†’ C:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\outputs\\xgb_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Build predictions for backtesting (Cell 14)\n",
    "# =========================\n",
    "y_val_hat = clf.predict(X_val)\n",
    "proba_val = getattr(clf, \"predict_proba\", lambda X: None)(X_val)\n",
    "\n",
    "classes_enc = np.asarray(getattr(clf, \"classes_\", np.array([0,1,2])))\n",
    "classes_dec = _inv[classes_enc]\n",
    "\n",
    "pred_dir_val = _inv[y_val_hat]\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"timestamp\": df.loc[val_idx, \"timestamp\"].values,\n",
    "    \"item\": df.loc[val_idx, \"item\"].values if \"item\" in df.columns else \"\",\n",
    "    \"mid_price\": df.loc[val_idx, \"mid_price\"].values if \"mid_price\" in df.columns else np.nan,\n",
    "    \"true_dir\": _inv[y_val],\n",
    "    \"pred_dir\": pred_dir_val,\n",
    "})\n",
    "\n",
    "pred_df[\"tradable\"] = (df.loc[val_idx, \"tradable\"].values.astype(\"int8\")\n",
    "                       if \"tradable\" in df.columns else 1)\n",
    "\n",
    "if proba_val is not None:\n",
    "    for k, lab in enumerate(classes_dec):\n",
    "        pred_df[f\"proba_{lab}\"] = proba_val[:, k].astype(\"float32\")\n",
    "\n",
    "pred_df[\"pred_label\"] = pred_dir_val.astype(\"int8\")\n",
    "if proba_val is not None:\n",
    "    buy_idx = int(np.where(classes_dec == 1)[0][0])\n",
    "    pred_df[\"pred_proba_buy\"] = proba_val[:, buy_idx].astype(\"float32\")\n",
    "else:\n",
    "    pred_df[\"pred_proba_buy\"] = (pred_df[\"pred_dir\"] == 1).astype(\"float32\")\n",
    "\n",
    "pred_df.to_csv(OUTPUT_PREDICTIONS, index=False)\n",
    "print(f\"[modular] Saved predictions â†’ {OUTPUT_PREDICTIONS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb324945839b6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Tuning backtest knobs with src.backtest.engine...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-19 16:14:04,491] A new study created in RDB with name: bt_knobs_v19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[optuna] completed trials: 200\n",
      "Best params: {'min_trade_amount': 43884673.97468845, 'min_confidence': 0.9319720261942077, 'exit_profit_threshold': 0.3864550992743331, 'stop_loss_threshold': 0.020089557364031098, 'persist_bars': 27, 'alpha': 9.454379110802929, 'min_confidence_streak': 0.7266526196524977}\n",
      "Best value: 15.445097521971016\n",
      "Summary: {'Final Capital': '2,849,292,332', 'Total Profit': '1,849,292,332', 'Num Trades': 120, 'Win Rate': '45.00%', 'Average Return / Trade': '15.66%', 'Average Win': '37.23%', 'Average Loss': '-1.99%', 'Gross Profit': '2,012,132,491', 'Gross Loss': '-162,840,159', 'Profit Factor': '12.36', 'Average Duration (min)': '330.17'}\n",
      "[modular] Best backtest summary:\n",
      "  Final Capital: 2,849,292,332\n",
      "  Total Profit: 1,849,292,332\n",
      "  Num Trades: 120\n",
      "  Win Rate: 45.00%\n",
      "  Average Return / Trade: 15.66%\n",
      "  Average Win: 37.23%\n",
      "  Average Loss: -1.99%\n",
      "  Gross Profit: 2,012,132,491\n",
      "  Gross Loss: -162,840,159\n",
      "  Profit Factor: 12.36\n",
      "  Average Duration (min): 330.17\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Backtest tuning + best backtest (Cell 15 alt)\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "from src.backtest.engine import tune_backtest_knobs\n",
    "\n",
    "print(\"[modular] Tuning backtest knobs with src.backtest.engine...\")\n",
    "\n",
    "TRADE_LOG_PATH = Path(config.XGB_TRADE_LOG_CSV)\n",
    "PLOTS_DIR = Path(config.XGB_TRADING_DIR)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRADE_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Run tuning on the same predictions CSV you already generate\n",
    "study, best_summary, best_trades, best_eq = tune_backtest_knobs(\n",
    "    pred_path=Path(OUTPUT_PREDICTIONS),   # uses the CSV you created earlier\n",
    "    study_name=\"bt_knobs_v20\",\n",
    "    storage_dir=\"backtests/db\",\n",
    "    total_trials=200,                     # adjust as needed\n",
    "    trade_log_path=TRADE_LOG_PATH,       # also saves best trades to CSV\n",
    "    initial_capital=1_000_000_000.0,\n",
    "    max_trades_per_minute=2,\n",
    "    spread_bps=10.0,\n",
    "    fee_bps=100.0,\n",
    "    slippage_bps=0.0,\n",
    "    median_window=30,\n",
    "    impact_cap_bps=200.0,\n",
    "    max_positions_per_item=1,\n",
    "    cooldown_minutes=0,\n",
    "    bar_seconds=60,\n",
    ")\n",
    "\n",
    "# Make results visible to the diagnostics cell\n",
    "trades = best_trades\n",
    "equity = best_eq\n",
    "summary = best_summary\n",
    "\n",
    "print(\"[modular] Best backtest summary:\")\n",
    "for k, v in best_summary.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "print(f\"[modular] Best trades saved to: {TRADE_LOG_PATH}\")\n",
    "print(f\"[modular] Optuna best params: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf50b1031d1843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modular] Saving plots to: C:\\Users\\reyno\\Documents\\GitHub\\Project-BLD\\outputs\\trading\\XGB_trading\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'equity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[modular] Saving plots to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPLOTS_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Equity curve\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mequity\u001b[49m):\n\u001b[32m     16\u001b[39m     fig = plt.figure(figsize=(\u001b[32m9\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m     17\u001b[39m     ax = plt.gca()\n",
      "\u001b[31mNameError\u001b[39m: name 'equity' is not defined"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Diagnostic plots (Cell 16)\n",
    "# =========================\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "def _save_fig(fig, name: str, dpi=160):\n",
    "    path = os.path.join(PLOTS_DIR, name)\n",
    "    fig.savefig(path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    return path\n",
    "\n",
    "print(f\"[modular] Saving plots to: {PLOTS_DIR}\")\n",
    "\n",
    "# Equity curve\n",
    "if len(equity):\n",
    "    fig = plt.figure(figsize=(9,3))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(equity[\"timestamp\"].values, equity[\"equity\"].values)\n",
    "    ax.set_title(\"Equity Over Time (Modular)\")\n",
    "    ax.set_xlabel(\"timestamp\")\n",
    "    ax.set_ylabel(\"equity\")\n",
    "    _save_fig(fig, \"equity_curve_modular.png\")\n",
    "\n",
    "    # Invested % curve\n",
    "    if \"invested_pct\" in equity.columns:\n",
    "        fig = plt.figure(figsize=(9,3))\n",
    "        ax = plt.gca()\n",
    "        ax.plot(equity[\"timestamp\"].values, 100*equity[\"invested_pct\"].values)\n",
    "        ax.set_title(\"Invested % of Equity Over Time (Modular)\")\n",
    "        ax.set_xlabel(\"timestamp\"); ax.set_ylabel(\"invested %\")\n",
    "        _save_fig(fig, \"invested_curve_modular.png\")\n",
    "\n",
    "    # Drawdown curve\n",
    "    e = equity[\"equity\"].astype(float).to_numpy()\n",
    "    peaks = np.maximum.accumulate(e)\n",
    "    dd = (e - peaks) / np.maximum(peaks, 1e-12)\n",
    "    fig = plt.figure(figsize=(9,2.5))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(equity[\"timestamp\"].values, 100*dd)\n",
    "    ax.set_title(f\"Drawdown (%) â€” Min: {100*dd.min():.2f}%\")\n",
    "    ax.set_xlabel(\"timestamp\"); ax.set_ylabel(\"drawdown %\")\n",
    "    _save_fig(fig, \"drawdown_curve_modular.png\")\n",
    "\n",
    "# Trade diagnostics\n",
    "if len(trades):\n",
    "    # PnL histogram\n",
    "    fig = plt.figure(figsize=(7,3))\n",
    "    ax = plt.gca()\n",
    "    ax.hist(trades[\"pnl\"].astype(float).values, bins=80)\n",
    "    ax.set_title(\"Trade PnL Histogram (Modular)\")\n",
    "    ax.set_xlabel(\"PnL\"); ax.set_ylabel(\"count\")\n",
    "    _save_fig(fig, \"trades_pnl_hist_modular.png\")\n",
    "\n",
    "    # Duration vs return scatter\n",
    "    if {\"duration_min\",\"return\"}.issubset(trades.columns):\n",
    "        fig = plt.figure(figsize=(6,4))\n",
    "        ax = plt.gca()\n",
    "        x = trades[\"duration_min\"].astype(float).values\n",
    "        y = trades[\"return\"].astype(float).values\n",
    "        ax.scatter(x, y, s=8, alpha=0.5)\n",
    "        ax.set_title(\"Trade Return vs Duration (Modular)\")\n",
    "        ax.set_xlabel(\"duration (min)\"); ax.set_ylabel(\"return\")\n",
    "        _save_fig(fig, \"trades_return_vs_duration_modular.png\")\n",
    "\n",
    "# Feature importance\n",
    "try:\n",
    "    booster = getattr(clf, \"get_booster\", lambda: None)()\n",
    "    if booster is not None:\n",
    "        try:\n",
    "            score = booster.get_score(importance_type='gain')\n",
    "        except Exception:\n",
    "            score = booster.get_score(importance_type='weight')\n",
    "        if score:\n",
    "            imp = pd.DataFrame({\"feature\": list(score.keys()),\n",
    "                                \"importance\": list(score.values())}).sort_values(\"importance\", ascending=False).head(25)\n",
    "            fig = plt.figure(figsize=(8,5))\n",
    "            ax = plt.gca()\n",
    "            ax.barh(imp[\"feature\"].values[::-1], imp[\"importance\"].values[::-1])\n",
    "            ax.set_title(\"Top 25 Features (XGBoost importance)\")\n",
    "            ax.set_xlabel(\"importance\"); ax.set_ylabel(\"feature\")\n",
    "            _save_fig(fig, \"xgb_feature_importance_top25_modular.png\")\n",
    "except Exception as e:\n",
    "    print(f\"[modular] Feature importance plot skipped: {e}\")\n",
    "\n",
    "print(\"[modular] Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
